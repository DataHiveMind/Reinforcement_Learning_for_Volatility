# ðŸ“˜ Reinforcement Learning for Volatility Alpha Capture

RLâ€‘Driven Volatility Forecasting and Allocation Using Market Microstructure & Unstructured Data

> **ðŸ†• Now with FinRL Integration!** - Advanced financial RL library with pre-built agents, ensemble methods, and optimization tools. See [FINRL_INTEGRATION.md](docs/FINRL_INTEGRATION.md) for details.
>
> **ðŸ“Š Data Source**: Uses Yahoo Finance (yfinance) for reliable, free equities data.

## ðŸ“Œ Overview

This project develops a reinforcement learning framework for capturing shortâ€‘horizon volatility alpha using:

Market microstructure features (orderâ€‘book imbalance, trade flow toxicity, queue dynamics)

Optionsâ€‘implied metrics (IV skew, termâ€‘structure curvature, volâ€‘ofâ€‘vol)

Unstructured data signals (news sentiment, embeddings, macroâ€‘uncertainty topics)

The goal is to build an RL agent that allocates capital across volatility strategies (skew, convexity, dispersion, volâ€‘carry) and predicts volatility breakouts before they occur.

This project is designed to mirror the research workflows used at top quant funds and PhDâ€‘level ML labs.

## ðŸš€ Quick Start

### 1. Create Conda Environment

```bash
# Create the environment
conda env create -f environment.yml

# Activate the environment
conda activate rl-volatility

# Register Jupyter kernel
python -m ipykernel install --user --name=rl-volatility --display-name="Python (RL-Volatility)"
```

Or use the setup script:

```bash
./setup_env.sh
```

### 2. Install Project

```bash
# Install in development mode
pip install -e ".[all]"
```

### 3. VS Code Setup

The workspace is pre-configured to use the `rl-volatility` conda environment. After creating the environment:

- Reload VS Code window (Cmd/Ctrl + Shift + P â†’ "Developer: Reload Window")
- Jupyter notebooks will automatically use the correct kernel

See [CONDA_SETUP.md](CONDA_SETUP.md) for detailed instructions.

## ðŸŽ¯ Research Objectives

Build a custom RL environment that simulates volatility dynamics using microstructure + options data

Engineer highâ€‘frequency alpha signals from orderâ€‘book and tradeâ€‘flow data

Integrate unstructured text features from news and macro transcripts

Train PPO/DDPG agents to learn volatilityâ€‘aware allocation policies

Evaluate performance using:

Sharpe ratio

Volatility prediction accuracy

Breakout detection recall

Regimeâ€‘dependent performance

Produce a reproducible, modular research pipeline suitable for realâ€‘world quant research

## ðŸ“‚ Project Structure

rl-volatility-alpha/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ data/
â”‚   â””â”€â”€ env/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ external/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 02_volatility_labels.ipynb
â”‚   â”œâ”€â”€ 03_microstructure_signals.ipynb
â”‚   â”œâ”€â”€ 04_env_sanity_checks.ipynb
â”‚   â””â”€â”€ 05_model_experiments.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ envs/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ signals/
â”‚   â”œâ”€â”€ training/
â”‚   â””â”€â”€ utils/
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ ppo_microstructure/
â”‚   â””â”€â”€ ddpg_microstructure/
â”‚
â””â”€â”€ tests/

## ðŸ§  Key Components

1. Market Microstructure Features
    - Extracted from orderâ€‘book & tradeâ€‘flow data:

    - Orderâ€‘book imbalance

    - Queue position & depth

    - Trade flow toxicity (ELO/VPINâ€‘style)

    - Shortâ€‘horizon realized volatility

    - Spread dynamics & liquidity shocks

2. Optionsâ€‘Implied Volatility Features
    - IV skew & term structure

    - Volâ€‘ofâ€‘vol

    - Smirk curvature

    - Realized vs implied spreads

3. Unstructured Data Signals
    - Using NLP + transformers:

    - News sentiment

    - Macroâ€‘uncertainty embeddings

    - Topicâ€‘modelâ€‘based volatility drivers

    - FOMC / earnings call latent factors

4. Reinforcement Learning Environment
    - Custom OpenAIâ€‘style environment:

    - State = microstructure + options + NLP features

    - Actions = volatility strategy allocation

    - Reward = volatilityâ€‘adjusted PnL, convexity capture, breakout detection

5. RL Agents
    - Implemented agents:

    - **PPO** (stable, robust for noisy signals)

    - **DDPG** (continuous action space for allocation weights)

    - **FinRL Integration** ðŸ†• (PPO, A2C, SAC, TD3, DDPG + ensembles)

    - Optional: SAC, TD3

## ðŸ“ˆ Evaluation Metrics

1. Sharpe ratio

2. Volatility prediction accuracy

3. Breakout detection recall/precision

4. Regimeâ€‘dependent performance

5. Turnover & transaction cost impact

6. Signal decay & horizon analysis

## ðŸ§ª Experiment Tracking

All experiments are logged under:
/experiments/
    /ppo_microstructure/
    /ddpg_microstructure/

Each experiment contains:

logs/
checkpoints/
metrics.json

## ðŸš€ Getting Started

Summary

## ðŸ“œ Research Motivation

Volatility is driven by:

microstructure imbalances

optionsâ€‘implied expectations

macroâ€‘uncertainty shocks

sentimentâ€‘driven flow

Traditional models (GARCH, HAR, linear factor models) struggle with:

nonlinear interactions

regime shifts

highâ€‘frequency microstructure noise

unstructured data

Reinforcement learning provides a framework for:

dynamic allocation

nonlinear state representations

adaptive policy learning

regimeâ€‘aware decision making

This project explores whether RL can capture volatility alpha more effectively than traditional models.
